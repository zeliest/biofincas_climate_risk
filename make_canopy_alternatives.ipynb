{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare the composition files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compositions = [\n",
    "    \"20250819__Cacao__AltaVerapaz\",\n",
    "    \"20250819__Cacao__DR_Cibao_Noroeste\",\n",
    "    \"20250819__Coffee__DR_Cibao_Noroeste\",\n",
    "    \"20250819__Coffee__Veracruz\",\n",
    "    \"20250819__Coffee__WesternHighlands\"\n",
    "]\n",
    "\n",
    "prefix = compositions[2]  # Extract the crop name from the first composition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Define output and input directories\n",
    "INPUT_DIR_VICTOR = Path(\"/Users/viggo/Documents/Programming/Consult/UNU/data\")\n",
    "OUTPUT_DIR = Path(\"/Users/viggo/Documents/Programming/Consult/UNU/biofincas_climate_risk/Results\")\n",
    "# Make a directory for the modified agroforestry systems in prefix\n",
    "OUTPUT_DIR = OUTPUT_DIR / prefix\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Define output and input directories\n",
    "INPUT_DIR_ZELIE = Path(\"/Users/viggo/Documents/Programming/Consult/UNU/biofincas_climate_risk/agroforestry_systems\")\n",
    "\n",
    "# Define file names\n",
    "file_name_Zelie = prefix + \".xlsx\"\n",
    "file_name_Victor = \"canopy_crop_composition.xlsx\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read Victors file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded sheet: present with 14 rows.\n",
      "+----+------------+-------------+-----------------+----------+------------------+--------------------+-------------------+-----------+-------------+---------------------+--------------------+------------------------+\n",
      "|    |   Latitude |   Longitude |   Elevation (m) | System   |   Plot size (ha) | Species            | Scientific name   | Role      |   Plants/ha |   Yield (t/ha/year) |   Price-per-tonnes |   Per-tree shading (%) |\n",
      "|----+------------+-------------+-----------------+----------+------------------+--------------------+-------------------+-----------+-------------+---------------------+--------------------+------------------------|\n",
      "|  0 |    17.3205 |    -93.1084 |             734 | Coffee   |                1 | Coffee (main crop) | Coffea arabica    | Main      |         730 |                0.73 |               1800 |                    0   |\n",
      "|  1 |    17.3205 |    -93.1084 |             734 | Coffee   |                1 | Guama              | Inga spp.         | Secondary |         144 |              nan    |                nan |                   25   |\n",
      "|  2 |    17.3205 |    -93.1084 |             734 | Coffee   |                1 | Bitter orange      | Citrus aurantium  | Secondary |           0 |                2.28 |                667 |                   49.8 |\n",
      "|  3 |    17.3205 |    -93.1084 |             734 | Coffee   |                1 | Sweet orange       | Citrus sinensis   | Secondary |           0 |                0.92 |                667 |                   35.3 |\n",
      "|  4 |    17.3205 |    -93.1084 |             734 | Coffee   |                1 | Sapote             | Pouteria sapota   | Secondary |           0 |                0.6  |               1500 |                   49.8 |\n",
      "+----+------------+-------------+-----------------+----------+------------------+--------------------+-------------------+-----------+-------------+---------------------+--------------------+------------------------+\n",
      "Loaded sheet: more_trees with 14 rows.\n",
      "+----+------------+-------------+-----------------+------------------+----------+--------------------+-------------------+-----------+-------------+\n",
      "|    |   Latitude |   Longitude |   Elevation (m) |   Plot size (ha) | System   | Species            | Scientific name   | Role      |   Plants/ha |\n",
      "|----+------------+-------------+-----------------+------------------+----------+--------------------+-------------------+-----------+-------------|\n",
      "|  0 |    17.3205 |    -93.1084 |             734 |                1 | Coffee   | Coffee (main crop) | Coffea arabica    | Main      |         730 |\n",
      "|  1 |    17.3205 |    -93.1084 |             734 |                1 | Coffee   | Guama              | Inga spp.         | Secondary |         150 |\n",
      "|  2 |    17.3205 |    -93.1084 |             734 |                1 | Coffee   | Bitter orange      | Citrus aurantium  | Secondary |           0 |\n",
      "|  3 |    17.3205 |    -93.1084 |             734 |                1 | Coffee   | Sweet orange       | Citrus sinensis   | Secondary |           0 |\n",
      "|  4 |    17.3205 |    -93.1084 |             734 |                1 | Coffee   | Sapote             | Pouteria sapota   | Secondary |           0 |\n",
      "+----+------------+-------------+-----------------+------------------+----------+--------------------+-------------------+-----------+-------------+\n",
      "Loaded sheet: even_more_trees with 14 rows.\n",
      "+----+------------+-------------+-----------------+------------------+----------+--------------------+-------------------+-----------+-------------+\n",
      "|    |   Latitude |   Longitude |   Elevation (m) |   Plot size (ha) | System   | Species            | Scientific name   | Role      |   Plants/ha |\n",
      "|----+------------+-------------+-----------------+------------------+----------+--------------------+-------------------+-----------+-------------|\n",
      "|  0 |    17.3205 |    -93.1084 |             734 |                1 | Coffee   | Coffee (main crop) | Coffea arabica    | Main      |         730 |\n",
      "|  1 |    17.3205 |    -93.1084 |             734 |                1 | Coffee   | Guama              | Inga spp.         | Secondary |         200 |\n",
      "|  2 |    17.3205 |    -93.1084 |             734 |                1 | Coffee   | Bitter orange      | Citrus aurantium  | Secondary |           0 |\n",
      "|  3 |    17.3205 |    -93.1084 |             734 |                1 | Coffee   | Sweet orange       | Citrus sinensis   | Secondary |           0 |\n",
      "|  4 |    17.3205 |    -93.1084 |             734 |                1 | Coffee   | Sapote             | Pouteria sapota   | Secondary |           0 |\n",
      "+----+------------+-------------+-----------------+------------------+----------+--------------------+-------------------+-----------+-------------+\n",
      "Loaded sheet: no_trees with 14 rows.\n",
      "+----+------------+-------------+-----------------+------------------+----------+--------------------+-------------------+-----------+-------------+\n",
      "|    |   Latitude |   Longitude |   Elevation (m) |   Plot size (ha) | System   | Species            | Scientific name   | Role      |   Plants/ha |\n",
      "|----+------------+-------------+-----------------+------------------+----------+--------------------+-------------------+-----------+-------------|\n",
      "|  0 |    17.3205 |    -93.1084 |             734 |                1 | Coffee   | Coffee (main crop) | Coffea arabica    | Main      |         730 |\n",
      "|  1 |    17.3205 |    -93.1084 |             734 |                1 | Coffee   | Guama              | Inga spp.         | Secondary |           0 |\n",
      "|  2 |    17.3205 |    -93.1084 |             734 |                1 | Coffee   | Bitter orange      | Citrus aurantium  | Secondary |           0 |\n",
      "|  3 |    17.3205 |    -93.1084 |             734 |                1 | Coffee   | Sweet orange       | Citrus sinensis   | Secondary |           0 |\n",
      "|  4 |    17.3205 |    -93.1084 |             734 |                1 | Coffee   | Sapote             | Pouteria sapota   | Secondary |           0 |\n",
      "+----+------------+-------------+-----------------+------------------+----------+--------------------+-------------------+-----------+-------------+\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "\n",
    "# get the number of sheets in the Excel file apart from the 'Current' sheet\n",
    "file = INPUT_DIR_VICTOR / file_name_Victor\n",
    "canopy_comps = pd.ExcelFile(file).sheet_names\n",
    "\n",
    "# Create a dictionary to hold the canopy composition data\n",
    "canopy_crop_victor_dict = {}\n",
    "for sheet in canopy_comps:\n",
    "    canopy_crop_victor_dict[sheet] = pd.read_excel(file, sheet_name=sheet)\n",
    "    print(f\"Loaded sheet: {sheet} with {len(canopy_crop_victor_dict[sheet])} rows.\")\n",
    "    print(tabulate(canopy_crop_victor_dict[sheet].head(), headers='keys', tablefmt='psql'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ZÃ©lies files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20250819__Coffee__DR_Cibao_Noroeste20250819__Coffee__Veracruz'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the number of sheets in the Excel file apart from the 'Current' sheet\n",
    "file = INPUT_DIR_ZELIE / file_name_Zelie\n",
    "canopy_comps_zelie = pd.ExcelFile(file).sheet_names\n",
    "\n",
    "# Modify the DataFrame to get the site_id and rename columns\n",
    "def modify_canopy_crop_df(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Generate unique site_id\n",
    "    df[\"Plot ID\"] = df.groupby([\"Latitude\", \"Longitude\"]).ngroup()\n",
    "\n",
    "    # Chnage ti string\n",
    "    df[\"Plot ID\"] = df[\"Plot ID\"].astype(str)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Create a dictionary to hold the canopy composition data\n",
    "canopy_crop_zelie_dict = {}\n",
    "for sheet in canopy_comps_zelie:\n",
    "    canopy_crop_zelie_dict[sheet] = pd.read_excel(file, sheet_name=sheet)\n",
    "    canopy_crop_zelie_dict[sheet] = modify_canopy_crop_df(canopy_crop_zelie_dict[sheet])\n",
    "    print(f\"Loaded sheet: {sheet} with {len(canopy_crop_zelie_dict[sheet])} rows.\")\n",
    "    print(tabulate(canopy_crop_zelie_dict[sheet], headers='keys', tablefmt='psql'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare the two 'present' composition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print only the first item\n",
    "print(f\"ZÃ©lies files: \\n{tabulate(canopy_crop_zelie_dict['present'], headers='keys', tablefmt='psql')}\")\n",
    "print(f\"Victors files:\\n{tabulate(canopy_crop_victor_dict['present'], headers='keys', tablefmt='psql')}\")\n",
    "\n",
    "# Print the columns missing in ZÃ©lies\n",
    "zelie_columns = set(canopy_crop_zelie_dict['present'].columns)\n",
    "victor_columns = set(canopy_crop_victor_dict['present'].columns)\n",
    "\n",
    "missing_in_zelie = victor_columns - zelie_columns\n",
    "missing_in_victor = zelie_columns - victor_columns\n",
    "\n",
    "print(f\"Columns missing in ZÃ©lies: {missing_in_zelie}\")\n",
    "print(f\"Columns missing in Victor: {missing_in_victor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get all the unique Species and Species Names acrross the sheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sheet in canopy_crop_zelie_dict:\n",
    "    print(f\"Sheet: {sheet}\")\n",
    "    print(tabulate(canopy_crop_zelie_dict[sheet].head(), headers='keys', tablefmt='psql'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import pandas as pd\n",
    "\n",
    "# Copy the ZÃ©lie present DataFrame to adjust it\n",
    "canopy_crop_zelie_dict_adjusted = copy.deepcopy(canopy_crop_zelie_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate unique Site ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Generate unique site_id\n",
    "for sheet, df in canopy_crop_zelie_dict_adjusted.items():\n",
    "    df[\"site_id\"] = df.groupby([\"Latitude\", \"Longitude\"]).ngroup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the default values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set estimates (USD per tonne)\n",
    "DR_TYPICAL_PRICE_TONNE_USD = {\n",
    "    \"Coffee\": 2580,\n",
    "    \"Cacao\":  3760,   # â matches coffeeâs $/ha at 0.5 t/ha\n",
    "    \"Banana\": 330,\n",
    "}\n",
    "\n",
    "DR_TYPICAL_YIELD = { # tonnes per hectare per year\n",
    "    \"Coffee\": 0.73,\n",
    "    \"Cacao\":  0.50,\n",
    "    \"Banana\": 22.64,\n",
    "}\n",
    "\n",
    "DR_TYPICAL_PLANTS_PER_HA = { # plants per hectare\n",
    "    \"Coffee\": 3000,\n",
    "    \"Cacao\":  1000,\n",
    "    \"Banana\": 2000,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Plants/ha for teh main crops coffe, cacao and banana to each sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# species we care about Scientific names, species names\n",
    "TARGETS = {\n",
    "    \"Coffea arabica\":   (\"Coffee (main crop)\", \"Coffee\"),\n",
    "    \"Theobroma cacao\":  (\"Cacao (main crop)\",  \"Cacao\"),\n",
    "    \"Musa spp.\":        (\"Banana\",             \"Banana\"),\n",
    "}\n",
    "\n",
    "def ensure_main_species_and_update_plants(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "\n",
    "    # ensure numeric for checks\n",
    "    out[\"Yield (t/ha/year)\"] = pd.to_numeric(out[\"Yield (t/ha/year)\"], errors=\"coerce\")\n",
    "    out[\"Plants/ha\"] = pd.to_numeric(out[\"Plants/ha\"], errors=\"coerce\")\n",
    "\n",
    "    rows_to_add = []\n",
    "\n",
    "    # group by Plot ID + Region as requested\n",
    "    for (plot_id, region), g in out.groupby([\"Plot ID\", \"Region\"], dropna=False):\n",
    "        base = g.iloc[0].to_dict()  # copy plot metadata\n",
    "\n",
    "        for sci_name, (common_label, key) in TARGETS.items():\n",
    "            present = g[g[\"Scientific name\"] == sci_name]\n",
    "\n",
    "            if not present.empty:\n",
    "                # update Plants/ha only where yield is known\n",
    "                idx = present.index[present[\"Yield (t/ha/year)\"].notna()]\n",
    "                if len(idx):\n",
    "                    out.loc[idx, \"Plants/ha\"] = DR_TYPICAL_PLANTS_PER_HA[key]\n",
    "            else:\n",
    "                # add a new row for this plot with Plants/ha = 0\n",
    "                new_row = {col: base.get(col, np.nan) for col in out.columns}\n",
    "                new_row[\"Scientific name\"] = sci_name\n",
    "                if \"Species\" in new_row:\n",
    "                    new_row[\"Species\"] = common_label\n",
    "                if \"Plants/ha\" in new_row:\n",
    "                    new_row[\"Plants/ha\"] = 0\n",
    "                if \"Yield (t/ha/year)\" in new_row:\n",
    "                    new_row[\"Yield (t/ha/year)\"] = np.nan\n",
    "                rows_to_add.append(new_row)\n",
    "\n",
    "    if rows_to_add:\n",
    "        out = pd.concat([out, pd.DataFrame(rows_to_add)], ignore_index=True)\n",
    "\n",
    "    # Sort the DataFrame by Plot ID and Region\n",
    "    out.sort_values(by=[\"Plot ID\", \"Region\", \"Scientific name\"], inplace=True)\n",
    "\n",
    "    return out\n",
    "\n",
    "# Do it for all sheets in the ZÃ©lie dictionary\n",
    "for sheet, df in canopy_crop_zelie_dict_adjusted.items():\n",
    "    canopy_crop_zelie_dict_adjusted[sheet] = ensure_main_species_and_update_plants(df)\n",
    "    # Print the adjusted DataFrame for the sheet\n",
    "    print(f\"Adjusted ZÃ©lie DataFrame for sheet '{sheet}':\\n{tabulate(canopy_crop_zelie_dict_adjusted[sheet], headers='keys', tablefmt='psql')}\")\n",
    "    print(f\"Adjusted ZÃ©lie DataFrame for sheet '{sheet}' has {len(canopy_crop_zelie_dict_adjusted[sheet])} rows.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the unique species, scientific names and shade levels across all alternatives "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# For all sheets except 'present', only store the columns\n",
    "unique_cols = [\"site_id\", \"Species\", \"Scientific name\", \"Per-tree shading (%)\"]\n",
    "\n",
    "# 1) Stack all sheets, tagging each row with its sheet idx\n",
    "stacked = pd.concat(\n",
    "    [df[unique_cols].assign(Source=idx)\n",
    "     for idx, (_, df) in enumerate(canopy_crop_zelie_dict_adjusted.items())],\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "# 2) Prefer rows that HAVE shade; within those, prefer the smallest sheet idx\n",
    "stacked[\"_shade_missing\"] = stacked[\"Per-tree shading (%)\"].isna()\n",
    "stacked = stacked.sort_values(\n",
    "    [\"site_id\", \"Species\", \"Scientific name\", \"_shade_missing\", \"Source\"],\n",
    "    ascending=[True, True, True, True, True]   # non-NaN first (False < True), then lowest idx\n",
    ")\n",
    "\n",
    "# 3) Keep the first occurrence per (site_id, Species, Scientific name)\n",
    "df_unique_species = (\n",
    "    stacked\n",
    "      .drop_duplicates(subset=[\"site_id\", \"Species\", \"Scientific name\"], keep=\"first\")\n",
    "      .drop(columns=[\"_shade_missing\"])\n",
    "      .reset_index(drop=True)\n",
    ")[[\"site_id\", \"Species\", \"Scientific name\", \"Per-tree shading (%)\", \"Source\"]]\n",
    "\n",
    "# If you want to see it:\n",
    "# from tabulate import tabulate\n",
    "print(tabulate(df_unique_species, headers='keys', tablefmt='psql'))\n",
    "\n",
    "# Drop the 'Source' column if not needed\n",
    "df_unique_species = df_unique_species.drop(columns=[\"Source\"])\n",
    "print(f\"Unique species DataFrame has {len(df_unique_species)} rows.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adjust so the other sheets only have limited columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "# For all sheets except 'present', only store the columns \n",
    "store_columns = [\"Plot ID\", \"Latitude\", \"Longitude\", \"Region\", \"System\", \"Plot size (ha)\", \"Species\", \"Scientific name\", \"Plants/ha\"]\n",
    "for sheet in canopy_crop_zelie_dict_adjusted:\n",
    "    if sheet != \"present\":\n",
    "        canopy_crop_zelie_dict_adjusted[sheet] = canopy_crop_zelie_dict_adjusted[sheet][store_columns]\n",
    "\n",
    "# For each sheet in the ZÃ©lies data, add the region key\n",
    "for sheet in canopy_crop_zelie_dict_adjusted:\n",
    "    canopy_crop_zelie_dict_adjusted[sheet][\"Region_key\"] = canopy_crop_zelie_dict_adjusted[sheet][\"Region\"].str.split(\" - \", n=1).str[0].str.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sheet, df in canopy_crop_zelie_dict_adjusted.items():\n",
    "    print(f\"Sheet: {sheet}\")\n",
    "    print(tabulate(df, headers='keys', tablefmt='psql'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adjust the 'present' sheet so to have a specific Species                   | Scientific name    |   Per-tree shading (%) taken from the other sheets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def backfill_species_any_sheet(\n",
    "    sheet_df: pd.DataFrame,\n",
    "    df_unique_species: pd.DataFrame,\n",
    "    present_df_for_site_map: pd.DataFrame\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Ensure each site (by site_id) in `sheet_df` contains all (Species, Scientific name)\n",
    "    pairs from `df_unique_species` for that site. Append missing rows with Plants/ha = 0.\n",
    "    If 'Per-tree shading (%)' exists in sheet_df, copy it from df_unique_species.\n",
    "\n",
    "    site_id mapping:\n",
    "      1) by exact 'Plot ID' to present\n",
    "      2) if still missing, by numeric suffix of Plot ID (e.g., 001, 002, 003)\n",
    "    \"\"\"\n",
    "    out = sheet_df.copy()\n",
    "\n",
    "    needed_min = {\"Plot ID\", \"Region\", \"System\", \"Species\", \"Scientific name\", \"Plants/ha\"}\n",
    "    missing = needed_min - set(out.columns)\n",
    "    if missing:\n",
    "        raise ValueError(f\"Sheet is missing required columns: {missing}\")\n",
    "\n",
    "    out[\"Plants/ha\"] = pd.to_numeric(out[\"Plants/ha\"], errors=\"coerce\")\n",
    "\n",
    "    need_unique = {\"site_id\",\"Species\",\"Scientific name\",\"Per-tree shading (%)\"}\n",
    "    if not need_unique.issubset(df_unique_species.columns):\n",
    "        raise ValueError(\"df_unique_species must have: site_id, Species, Scientific name, Per-tree shading (%)\")\n",
    "\n",
    "    # --- build site_id map from present ---\n",
    "    pres = present_df_for_site_map[[\"Plot ID\",\"site_id\"]].drop_duplicates().copy()\n",
    "    pres[\"_suffix\"] = pres[\"Plot ID\"].str.extract(r\"(\\d+)$\", expand=False)\n",
    "\n",
    "    added_temp_site = False\n",
    "    if \"site_id\" not in out.columns:\n",
    "        out = out.merge(pres[[\"Plot ID\",\"site_id\"]], on=\"Plot ID\", how=\"left\")\n",
    "        added_temp_site = True\n",
    "\n",
    "    # if still missing site_id, map by numeric suffix\n",
    "    if out[\"site_id\"].isna().any():\n",
    "        out[\"_suffix\"] = out[\"Plot ID\"].str.extract(r\"(\\d+)$\", expand=False)\n",
    "        out = out.merge(\n",
    "            pres[[\"_suffix\",\"site_id\"]].rename(columns={\"site_id\":\"site_id_by_suffix\"}),\n",
    "            on=\"_suffix\",\n",
    "            how=\"left\"\n",
    "        )\n",
    "        out[\"site_id\"] = out[\"site_id\"].fillna(out[\"site_id_by_suffix\"])\n",
    "        out = out.drop(columns=[c for c in [\"_suffix\",\"site_id_by_suffix\"] if c in out.columns])\n",
    "\n",
    "    # If we still have no site_id for a row, we canât backfill it\n",
    "    existing = set(zip(out[\"site_id\"], out[\"Species\"], out[\"Scientific name\"]))\n",
    "\n",
    "    new_rows = []\n",
    "    for sid, grp in df_unique_species.groupby(\"site_id\", dropna=False):\n",
    "        if pd.isna(sid):\n",
    "            continue\n",
    "        base_rows = out[out[\"site_id\"] == sid]\n",
    "        if base_rows.empty:\n",
    "            continue\n",
    "\n",
    "        base = base_rows.iloc[0].to_dict()\n",
    "        for _, r in grp.iterrows():\n",
    "            key = (sid, r[\"Species\"], r[\"Scientific name\"])\n",
    "            if key in existing:\n",
    "                continue\n",
    "\n",
    "            new_row = {col: base.get(col, np.nan) for col in out.columns}\n",
    "            new_row[\"site_id\"] = sid\n",
    "            new_row[\"Species\"] = r[\"Species\"]\n",
    "            new_row[\"Scientific name\"] = r[\"Scientific name\"]\n",
    "            new_row[\"Plants/ha\"] = 0\n",
    "            if \"Per-tree shading (%)\" in out.columns:\n",
    "                new_row[\"Per-tree shading (%)\"] = r[\"Per-tree shading (%)\"]\n",
    "            new_rows.append(new_row)\n",
    "\n",
    "    if new_rows:\n",
    "        out = pd.concat([out, pd.DataFrame(new_rows)], ignore_index=True)\n",
    "\n",
    "    if added_temp_site:\n",
    "        out = out.drop(columns=[\"site_id\"])\n",
    "\n",
    "    sort_cols = [c for c in [\"Plot ID\",\"site_id\",\"Species\",\"Scientific name\"] if c in out.columns]\n",
    "    return out.sort_values(sort_cols).reset_index(drop=True)\n",
    "\n",
    "\n",
    "# Keep 'present' with full columns (including site_id) so we can map site_id by Plot ID.\n",
    "present_full = canopy_crop_zelie_dict_adjusted[\"present\"]\n",
    "\n",
    "for name, df in canopy_crop_zelie_dict_adjusted.items():\n",
    "    canopy_crop_zelie_dict_adjusted[name] = backfill_species_any_sheet(\n",
    "        sheet_df=df,\n",
    "        df_unique_species=df_unique_species,\n",
    "        present_df_for_site_map=present_full\n",
    "    )\n",
    "    # Print the adjusted sheets\n",
    "    print(f\"Adjusted ZÃ©lie DataFrame for sheet '{name}':\\n{tabulate(canopy_crop_zelie_dict_adjusted[name], headers='keys', tablefmt='psql')}\")\n",
    "    print(f\"Adjusted ZÃ©lie DataFrame for sheet '{name}' has {len(canopy_crop_zelie_dict_adjusted[name])} rows.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sheet in canopy_crop_zelie_dict_adjusted:\n",
    "    print(f\"Sheet: {sheet}\")\n",
    "    print(tabulate(canopy_crop_zelie_dict_adjusted[sheet], headers='keys', tablefmt='psql'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1) Define main crops (everything else defaults to \"Secondary\")\n",
    "main_species = [\"Coffea arabica\", \"Theobroma cacao\"]\n",
    "\n",
    "# 2) Collect all unique species across the ZÃ©lie dict\n",
    "all_species = set()\n",
    "for df in canopy_crop_zelie_dict_adjusted.values():\n",
    "    all_species.update(df[\"Scientific name\"].unique())\n",
    "\n",
    "# 3) Build role mapping dynamically\n",
    "role_records = []\n",
    "for sp in sorted(all_species):\n",
    "    role = \"Main\" if sp in main_species else \"Secondary\"\n",
    "    role_records.append({\"Scientific name\": sp, \"Role\": role})\n",
    "\n",
    "role_df = pd.DataFrame(role_records)\n",
    "\n",
    "print(\"Role DataFrame:\")\n",
    "print(tabulate(role_df, headers=\"keys\", tablefmt=\"psql\"))\n",
    "\n",
    "# 4) Merge role info into each sheet\n",
    "for sheet, df in canopy_crop_zelie_dict_adjusted.items():\n",
    "    canopy_crop_zelie_dict_adjusted[sheet] = df.merge(role_df, on=\"Scientific name\", how=\"left\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update the present composition to match the input for the cost-benefit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zelie_present_df = canopy_crop_zelie_dict_adjusted['present']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop the yield column and add the region key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the yield\n",
    "zelie_present_df.drop(columns=[\"Yield (t/ha/year)\"], inplace=True, errors='ignore')\n",
    "#zelie_present_df[\"Region_key\"] = zelie_present_df[\"Region\"].str.split(\" - \", n=1).str[0].str.strip()\n",
    "print(f\"ZÃ©lies adjusted files after dropping yield: \\n{tabulate(zelie_present_df, headers='keys', tablefmt='psql')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Yield and price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "\n",
    "FX = 50.0  # RD$ -> USD, Price/tonne = rd_per_kg * 1000 / FX\n",
    "\n",
    "# 1) DR fruit table (kg/plant + RD$/kg) -> Tonnes/plant + Price/tonnes (USD)\n",
    "rows_rd = [\n",
    "    {\"Region_key\": \"DR\", \"Scientific name\": \"Citrus spp.\",      \"Kg/plant\": 40, \"rd_per_kg\": 40},\n",
    "    {\"Region_key\": \"DR\", \"Scientific name\": \"Persea americana\", \"Kg/plant\": 50, \"rd_per_kg\": 30},\n",
    "    {\"Region_key\": \"DR\", \"Scientific name\": \"Pouteria sapota\",  \"Kg/plant\": 40, \"rd_per_kg\": 90},\n",
    "    {\"Region_key\": \"DR\", \"Scientific name\": \"Castanea spp.\",    \"Kg/plant\": 70, \"rd_per_kg\": 80},\n",
    "]\n",
    "df1 = pd.DataFrame(rows_rd)\n",
    "df1[\"Tonnes/plant\"] = df1[\"Kg/plant\"] / 1000.0\n",
    "df1[\"Price/tonnes (USD)\"] = (df1[\"rd_per_kg\"] * 1000.0 / FX).round(2)\n",
    "df1 = df1.drop(columns=[\"rd_per_kg\"])[[\"Region_key\",\"Scientific name\",\"Kg/plant\",\"Tonnes/plant\",\"Price/tonnes (USD)\"]]\n",
    "\n",
    "\n",
    "# Update your 'typ' list (Coffee already has 1800)\n",
    "typ = [\n",
    "    {\"Region_key\":\"DR\",\"Scientific name\":\"Coffea arabica\",\"Yield (t/ha/yr)\":DR_TYPICAL_YIELD[\"Coffee\"],\"Plants/ha\":DR_TYPICAL_PLANTS_PER_HA[\"Coffee\"],\"Price/tonnes (USD)\":DR_TYPICAL_PRICE_TONNE_USD[\"Coffee\"]},\n",
    "    {\"Region_key\":\"DR\",\"Scientific name\":\"Theobroma cacao\",\"Yield (t/ha/yr)\":DR_TYPICAL_YIELD[\"Cacao\"],\"Plants/ha\":DR_TYPICAL_PLANTS_PER_HA[\"Cacao\"],\"Price/tonnes (USD)\":DR_TYPICAL_PRICE_TONNE_USD[\"Cacao\"]},\n",
    "    {\"Region_key\":\"DR\",\"Scientific name\":\"Musa spp.\",\"Yield (t/ha/yr)\": DR_TYPICAL_YIELD[\"Banana\"],\"Plants/ha\":DR_TYPICAL_PLANTS_PER_HA[\"Banana\"],\"Price/tonnes (USD)\":DR_TYPICAL_PRICE_TONNE_USD[\"Banana\"]},\n",
    "]\n",
    "df2 = pd.DataFrame(typ)\n",
    "df2[\"Tonnes/plant\"] = (df2[\"Yield (t/ha/yr)\"] / df2[\"Plants/ha\"]).round(6)\n",
    "df2[\"Kg/plant\"] = (df2[\"Tonnes/plant\"] * 1000).round(3)\n",
    "df2 = df2[[\"Region_key\",\"Scientific name\",\"Kg/plant\",\"Tonnes/plant\",\"Price/tonnes (USD)\"]]\n",
    "\n",
    "# 3) Combine\n",
    "yield_price_df = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "# 4) Duplicate Citrus genus values to species-level for ZÃ©lieâs rows\n",
    "species_cost_mapping = {\n",
    "    \"Citrus aurantium\": \"Citrus spp.\",\n",
    "    \"Citrus sinensis\":  \"Citrus spp.\",\n",
    "}\n",
    "# 3) Duplicate rows for mapped species\n",
    "def duplicate_species(df, species_cost_mapping):\n",
    "    \"\"\"\n",
    "    Duplicate rows in costs_df_expanded for species in species_cost_mapping.\n",
    "    Each original species will have its mapped name replaced with the original name.\n",
    "    \"\"\"\n",
    "    expanded_df = df.copy()\n",
    "    for original_name, mapped_name in species_cost_mapping.items():\n",
    "        if mapped_name in expanded_df[\"Scientific name\"].values:\n",
    "            row_to_copy = expanded_df[expanded_df[\"Scientific name\"] == mapped_name].copy()\n",
    "            row_to_copy[\"Scientific name\"] = original_name\n",
    "            expanded_df = pd.concat([expanded_df, row_to_copy], ignore_index=True)\n",
    "    return expanded_df\n",
    "\n",
    "yield_price_df = duplicate_species(yield_price_df, species_cost_mapping)\n",
    "\n",
    "# (Optional) drop the genus Citrus spp. row if you only want species-level:\n",
    "# yield_price_df = yield_price_df[yield_price_df[\"Scientific name\"] != \"Citrus spp.\"]\n",
    "\n",
    "# Drop the 'Region_key' column if not needed\n",
    "yield_price_df = yield_price_df.drop(columns=[\"Region_key\"], errors='ignore')\n",
    "\n",
    "yield_price_df = yield_price_df.sort_values([\"Scientific name\"]).reset_index(drop=True)\n",
    "print(tabulate(yield_price_df, headers=\"keys\", tablefmt=\"psql\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from heapq import merge\n",
    "from math import cos\n",
    "import pandas as pd\n",
    "\n",
    "# Manual USD costs per tree (RD$ nursery + planting; maintenance = avg of yearly maint.)\n",
    "costs_dict_usd = {\n",
    "    \"Inga spp.\": {\n",
    "        \"Region_key\": \"DR\",\n",
    "        \"Planting cost (per tree)\": 1.50,  # (50 + 25) / 50\n",
    "        \"Maintenance cost (per tree)\": 0.88,  # (20+30+50+75)/4 / 50\n",
    "    },\n",
    "    \"Gliricidia sepium\": {\n",
    "        \"Region_key\": \"DR\",\n",
    "        \"Planting cost (per tree)\": 1.30,  # (30 + 35) / 50\n",
    "        \"Maintenance cost (per tree)\": 0.75,  # (20+30+50+50)/4 / 50\n",
    "    },\n",
    "    \"Citrus spp.\": {\n",
    "        \"Region_key\": \"DR\",\n",
    "        \"Planting cost (per tree)\": 1.10,  # (30 + 25) / 50\n",
    "        \"Maintenance cost (per tree)\": 0.55,  # (20+30+30+30)/4 / 50\n",
    "    },\n",
    "    \"Persea americana\": {\n",
    "        \"Region_key\": \"DR\",\n",
    "        \"Planting cost (per tree)\": 1.10,  # (30 + 25) / 50\n",
    "        \"Maintenance cost (per tree)\": 0.55,  # same profile\n",
    "    },\n",
    "    \"Pouteria sapota\": {\n",
    "        \"Region_key\": \"DR\",\n",
    "        \"Planting cost (per tree)\": 1.50,  # (50 + 25) / 50\n",
    "        \"Maintenance cost (per tree)\": 0.55,  # same profile\n",
    "    },\n",
    "    \"Castanea spp.\": {\n",
    "        \"Region_key\": \"DR\",\n",
    "        \"Planting cost (per tree)\": 6.80,  # (315 + 25) / 50\n",
    "        \"Maintenance cost (per tree)\": 0.55,  # (20+30+30+30)/4 / 50\n",
    "    },\n",
    "}\n",
    "\n",
    "# -> DataFrame\n",
    "costs_df = (\n",
    "    pd.DataFrame.from_dict(costs_dict_usd, orient=\"index\")\n",
    "      .reset_index()\n",
    "      .rename(columns={\"index\": \"Scientific name\"})\n",
    ")[[\"Region_key\", \"Scientific name\", \"Planting cost (per tree)\", \"Maintenance cost (per tree)\"]]\n",
    "\n",
    "# 3) Duplicate rows for mapped species\n",
    "def duplicate_species(df, species_cost_mapping):\n",
    "    \"\"\"\n",
    "    Duplicate rows in costs_df_expanded for species in species_cost_mapping.\n",
    "    Each original species will have its mapped name replaced with the original name.\n",
    "    \"\"\"\n",
    "    expanded_df = df.copy()\n",
    "    for original_name, mapped_name in species_cost_mapping.items():\n",
    "        if mapped_name in expanded_df[\"Scientific name\"].values:\n",
    "            row_to_copy = expanded_df[expanded_df[\"Scientific name\"] == mapped_name].copy()\n",
    "            row_to_copy[\"Scientific name\"] = original_name\n",
    "            expanded_df = pd.concat([expanded_df, row_to_copy], ignore_index=True)\n",
    "    return expanded_df\n",
    "\n",
    "# Drop the 'Region_key' column if not needed\n",
    "costs_df = costs_df.drop(columns=[\"Region_key\"], errors='ignore')\n",
    "\n",
    "print(\"Expanded costs DataFrame:\")\n",
    "costs_df = duplicate_species(costs_df, species_cost_mapping)\n",
    "print(tabulate(costs_df, headers='keys', tablefmt='psql'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add the data frame to the ZÃ©lies data frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge the data frame and calculate the new yield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the ZÃ©lie present DataFrame to adjust it\n",
    "zelie_present_adjusted_df = zelie_present_df.copy()\n",
    "\n",
    "# Add the region key to the DataFrame\n",
    "#zelie_present_adjusted_df[\"Region_key\"] = zelie_present_adjusted_df[\"Region\"].str.split(\" - \", n=1).str[0].str.strip()\n",
    "\n",
    "# Drop the yield\n",
    "zelie_present_df.drop(columns=[\"Yield (t/ha/year)\"], inplace=True, errors='ignore')\n",
    "\n",
    "# Merge yield_price_df with zelie_present_adjusted_df\n",
    "zelie_present_adjusted_df = zelie_present_adjusted_df.merge(\n",
    "    yield_price_df,\n",
    "    on=[ \"Scientific name\"],\n",
    "    how=\"left\",\n",
    "    suffixes=(\"\", \"_yield_price\")\n",
    ")\n",
    "\n",
    "# Calculate the new yield\n",
    "zelie_present_adjusted_df[\"Yield (t/ha/year)\"] = (\n",
    "    zelie_present_adjusted_df[\"Tonnes/plant\"] * zelie_present_adjusted_df[\"Plants/ha\"]\n",
    ")\n",
    "\n",
    "# Add the costs_df_expanded to zelie_present_adjusted_df\n",
    "zelie_present_adjusted_df = zelie_present_adjusted_df.merge(costs_df, on=[ \"Scientific name\"], how=\"left\")\n",
    "\n",
    "# Reorder columns to match the desired output\n",
    "new_order_columns = [\"Plot ID\",\n",
    "                    #\"site_id\",\n",
    "    \"Region\",\n",
    "   #\"Region_key\",\n",
    "    \"Latitude\",\n",
    "    \"Longitude\",\n",
    "    \"System\",\n",
    "    \"Plot size (ha)\",\n",
    "    \"Species\",\n",
    "    \"Scientific name\",\n",
    "    \"Role\",\n",
    "    \"Plants/ha\",\n",
    "    \"Kg/plant\",\n",
    "    \"Tonnes/plant\",\n",
    "    \"Yield (t/ha/year)\",\n",
    "    \"Price/tonnes (USD)\",\n",
    "    \"Per-tree shading (%)\",\n",
    "    \"Planting cost (per tree)\",\n",
    "    \"Maintenance cost (per tree)\"\n",
    "]\n",
    "zelie_present_adjusted_df = zelie_present_adjusted_df[new_order_columns]\n",
    "\n",
    "# Print the final adjusted DataFrame\n",
    "print(tabulate(zelie_present_adjusted_df, headers='keys', tablefmt='psql'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns to check for missing values\n",
    "check_cols = [\n",
    "    \"Planting cost (per tree)\",\n",
    "    \"Maintenance cost (per tree)\",\n",
    "    \"Tonnes/plant\",\n",
    "    \"Price/tonnes (USD)\"\n",
    "]\n",
    "\n",
    "# Filter for rows with NaN in any of the check columns\n",
    "df = zelie_present_adjusted_df.copy()\n",
    "missing_df = df[df[check_cols].isna().any(axis=1)]\n",
    "\n",
    "# Keep only Scientific name and Region, drop duplicates\n",
    "unique_missing = missing_df[[\"Scientific name\", \"Yield (t/ha/year)\"] + check_cols].drop_duplicates()\n",
    "print(tabulate(unique_missing, headers='keys', tablefmt='psql'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the new  Yield (t/ha/year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# df is your merged ZÃ©lie table (the one you showed last)\n",
    "df = zelie_present_adjusted_df.copy()\n",
    "\n",
    "# Make sure inputs are numeric\n",
    "df[\"Plants/ha\"] = pd.to_numeric(df[\"Plants/ha\"], errors=\"coerce\")\n",
    "df[\"Tonnes/plant\"] = pd.to_numeric(df[\"Tonnes/plant\"], errors=\"coerce\")\n",
    "df[\"Yield (t/ha/year)\"] = pd.to_numeric(df[\"Yield (t/ha/year)\"], errors=\"coerce\")\n",
    "\n",
    "# Candidate yield per ha\n",
    "candidate = df[\"Plants/ha\"] * df[\"Tonnes/plant\"]\n",
    "\n",
    "# Fill only where Yield (t/ha/year) is NaN\n",
    "mask = df[\"Yield (t/ha/year)\"].isna() & candidate.notna()\n",
    "df.loc[mask, \"Yield (t/ha/year)\"] = candidate[mask]\n",
    "\n",
    "# (optional) round to 2â3 decimals\n",
    "df[\"Yield (t/ha/year)\"] = df[\"Yield (t/ha/year)\"].round(3)\n",
    "\n",
    "# Update the DataFrame with the new Yield (t/ha/year)\n",
    "zelie_present_adjusted_df = df\n",
    "\n",
    "print(\"Updated DataFrame with Yield (t/ha/year):\")\n",
    "print(tabulate(zelie_present_adjusted_df, headers='keys', tablefmt='psql'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adjust prices to make resonable analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def adjust_secondary_econ(\n",
    "    df: pd.DataFrame,\n",
    "    price_mult: float = 1.0,       # e.g., 0.8 lowers prices by 20%\n",
    "    plant_cost_mult: float = 1.0,  # e.g., 0.9 lowers planting cost by 10%\n",
    "    maint_cost_mult: float = 1.0,  # e.g., 0.75 lowers maintenance by 25%\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Return a copy of df where rows with Role == 'Secondary' have their\n",
    "    price and per-tree costs scaled by the given multipliers.\n",
    "    (NaNs remain NaN.)\n",
    "    \"\"\"\n",
    "    out = df.copy()\n",
    "    sec = out[\"Role\"].eq(\"Secondary\")\n",
    "\n",
    "    if \"Price/tonnes (USD)\" in out:\n",
    "        out.loc[sec, \"Price/tonnes (USD)\"] = out.loc[sec, \"Price/tonnes (USD)\"] * price_mult\n",
    "    if \"Planting cost (per tree)\" in out:\n",
    "        out.loc[sec, \"Planting cost (per tree)\"] = out.loc[sec, \"Planting cost (per tree)\"] * plant_cost_mult\n",
    "    if \"Maintenance cost (per tree)\" in out:\n",
    "        out.loc[sec, \"Maintenance cost (per tree)\"] = out.loc[sec, \"Maintenance cost (per tree)\"] * maint_cost_mult\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "# 1) Make fruit shade less dominant and bump O&M for all secondary trees\n",
    "zelie_present_adjusted_incl_price_df = adjust_secondary_econ(\n",
    "    zelie_present_adjusted_df,\n",
    "    price_mult=1.0,                      # 70% of previous price for Secondary (fruit shade)\n",
    "    plant_cost_mult=1.0,                 # 0% chnage planting cost\n",
    "    maint_cost_mult=1.0,                 # 0% chnage maintenance\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate alterantives\n",
    "\n",
    "- Change crops, e.g., coffe -> cacao\n",
    "- Increase canopy (%) from present\n",
    "- Add mixture for given condition, e.g., heat resilient (already taken care of in ZÃ©lies code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from tabulate import tabulate\n",
    "\n",
    "excel_dict = copy.deepcopy(canopy_crop_zelie_dict_adjusted)\n",
    "\n",
    "# Update the 'present' sheet with the adjusted DataFrame\n",
    "excel_dict[\"present\"] = zelie_present_adjusted_incl_price_df\n",
    "\n",
    "# # Define the range of adjustments for canopy (e.g., -10% to +10% in steps of 5%)\n",
    "# adjustments = np.linspace(-0.80, 0.80, num=10)  # from -10% to +10% in 5 steps\n",
    "\n",
    "# results = {}  # store DataFrames keyed by adjustment value\n",
    "\n",
    "# for adj in adjustments:\n",
    "#     df_adjusted = zelie_present_adjusted_df[store_columns + [\"Role\"]].copy()\n",
    "\n",
    "#     # Apply adjustment only to rows where Role == \"Secondary\"\n",
    "#     df_adjusted[\"Plants/ha\"] = df_adjusted[\"Plants/ha\"].where(\n",
    "#         df_adjusted[\"Role\"] != \"Secondary\",\n",
    "#         df_adjusted[\"Plants/ha\"] * (1 + adj)\n",
    "#     )\n",
    "\n",
    "#     # Round to nearest integer\n",
    "#     df_adjusted[\"Plants/ha\"] = df_adjusted[\"Plants/ha\"].round().astype(int)\n",
    "\n",
    "#     # Store the adjusted DataFrame\n",
    "#     results[adj] = df_adjusted\n",
    "\n",
    "#     # Optional: print a sample for inspection\n",
    "#     print(f\"\\nAdjustment: {adj*100:.0f}%\")\n",
    "#     print(tabulate(df_adjusted, headers=\"keys\", tablefmt=\"psql\"))\n",
    "\n",
    "#     # Save the adjusted DataFrame to the dictionary\n",
    "#     excel_dict[f\"present_adjusted_{int(adj*100)} %\"] = df_adjusted\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Switch cacaco to coffe but have the same present canopy compostion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_cacao = canopy_crop_zelie_dict_adjusted['present'][store_columns + [\"Role\"]].copy()\n",
    "print(tabulate(df_new_cacao, headers='keys', tablefmt='psql'))\n",
    "\n",
    "# Update the Scientific name for Cacao by setting Plants/ha to 0\n",
    "df_new_cacao.loc[df_new_cacao['Scientific name'] == 'Theobroma cacao', 'Plants/ha'] = 0\n",
    "# Update the Scientific name for Coffe by setting \n",
    "df_new_cacao.loc[df_new_cacao['Scientific name'] == 'Coffea arabica', 'Plants/ha'] = DR_TYPICAL_PLANTS_PER_HA[\"Coffee\"]\n",
    "\n",
    "print(tabulate(df_new_cacao, headers='keys', tablefmt='psql'))\n",
    "\n",
    "# put back to the excel_dict\n",
    "excel_dict['cacao_to_coffee'] = df_new_cacao\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save excel version "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the adjusted DataFrame to an Excel file\n",
    "file_name = file_name_Zelie.replace(\".xlsx\", \"_adjusted_canopy_crop_composition.xlsx\")\n",
    "output_file = OUTPUT_DIR / file_name\n",
    "with pd.ExcelWriter(output_file, engine='xlsxwriter') as writer:\n",
    "    for sheet_name, df in excel_dict.items():\n",
    "        df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "        print(f\"Saved sheet: {sheet_name} with {len(df)} rows.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "climada_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
