{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63049b7b-2027-402d-a7b2-4017cdb0d89a",
   "metadata": {},
   "source": [
    "# TerraClimate Data Download & Processing\n",
    "\n",
    "This notebook automates the download and preprocessing of **TerraClimate** data for a selected region of interest.  \n",
    "The current setup extracts data for a bounding box covering the three countries of interest.\n",
    "\n",
    "## What it does\n",
    "\n",
    "1. **Download**  \n",
    "   - Retrieves monthly TerraClimate NetCDF files from the official server.  \n",
    "   - Variables include temperature, precipitation, evapotranspiration, vapour pressure, wind speed, and others relevant for crop suitability modelling.  \n",
    "   - Each full dataset for one scenario (e.g. one variable across all years) is approximately **600 MB**.\n",
    "\n",
    "2. **Crop & Subset**  \n",
    "   - Crops the global dataset to the bounding box around the three target countries.  \n",
    "   - Keeps only the required region, reducing file size and computation time.\n",
    "\n",
    "3. **Process & Save**  \n",
    "   - Extracts and stores the climatological variables needed for **suitability modelling** of agroforestry systems.  \n",
    "   - Saves processed files in a structured format for later use.\n",
    "\n",
    "## Notes\n",
    "\n",
    "- Ensure that output paths are correctly set before running.  \n",
    "- Depending on network speed, downloading the full set of variables can take time.  \n",
    "- Cropped and processed data are much lighter than the full global files.\n",
    "- Check that the base directory is well defined in the config.py file in the parent directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e385d5ff-c9e5-4ba9-bffa-9abae8717b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# --- Use cwd when __file__ isn't available (Jupyter/IPython) ---\n",
    "this_dir = Path().resolve()        # current working directory\n",
    "parent_dir = this_dir.parent\n",
    "sys.path.insert(0, str(parent_dir))\n",
    "\n",
    "\n",
    "from config import DATA_DIR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6bffbf-f578-4e43-b91f-a186e8689c16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import xarray as xr\n",
    "from config import DATA_DIR\n",
    "# ========================\n",
    "# Settings\n",
    "# ========================\n",
    "output_dir = DATA_DIR / \"terra_climate\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "years = range(1985, 2023)\n",
    "variables = [\"tmin\",\"tmax\",\"pet\", \"ppt\",\"aet\", \"def\", \"srad\", \"vap\", \"ws\", \"vpd\"]\n",
    "lat_bounds = (25, 10)\n",
    "lon_bounds = (-115, -50)\n",
    "\n",
    "# ========================\n",
    "# Helper function\n",
    "# ========================\n",
    "def download_and_crop(var, year):\n",
    "    filename = f\"TerraClimate_{var}_{year}.nc\"\n",
    "    url = f\"http://thredds.northwestknowledge.net:8080/thredds/fileServer/TERRACLIMATE_ALL/data/{filename}\"\n",
    "    print(f\"üîÑ Downloading {url}\")\n",
    "    try:\n",
    "        # Download full file to disk\n",
    "        response = requests.get(url, timeout=120)\n",
    "        response.raise_for_status()\n",
    "        with open(filename, \"wb\") as f:\n",
    "            f.write(response.content)\n",
    "\n",
    "        # Open, shift lon, crop, save\n",
    "        ds = xr.open_dataset(filename)\n",
    "        ds = ds.assign_coords(lon=(((ds.lon + 180) % 360) - 180))\n",
    "        ds_crop = ds[var].sel(lat=slice(*lat_bounds), lon=slice(*lon_bounds))\n",
    "\n",
    "        out_path = os.path.join(output_dir, f\"TerraClimate_{var}_{year}_CA.nc\")\n",
    "        ds_crop.to_netcdf(out_path, mode=\"w\")\n",
    "        print(f\"‚úÖ Saved to {out_path}\")\n",
    "\n",
    "        # Clean up temp file\n",
    "        os.remove(filename)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed for {var} {year}: {e}\")\n",
    "\n",
    "# ========================\n",
    "# Run batch download\n",
    "# ========================\n",
    "for var in variables:\n",
    "    for year in years:\n",
    "        download_and_crop(var, year)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ca3645-33ae-49af-b6c2-bf0fda30d0e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import os\n",
    "import requests\n",
    "\n",
    "# ========================\n",
    "# Settings\n",
    "# ========================\n",
    "scenario = \"plus2C\"\n",
    "prefix = \"2c\"\n",
    "output_dir = DATA_DIR / \"terra_climate_scenarios_ncss/plus2C\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "years = range(1985, 2015)\n",
    "lat_bounds = (25,10)\n",
    "lon_bounds = (-115, -50)\n",
    "\n",
    "\n",
    "# ========================\n",
    "# Helper function\n",
    "# ========================\n",
    "def download_and_crop(var, year):\n",
    "    filename = f\"TerraClimate_{prefix}_{var}_{year}.nc\"\n",
    "    url = f\"http://thredds.northwestknowledge.net:8080/thredds/fileServer/TERRACLIMATE_ALL/data_{scenario}/{filename}\"\n",
    "    print(f\"üîÑ Accessing {url}\")\n",
    "    try:\n",
    "        response = requests.get(url, timeout=60)\n",
    "        response.raise_for_status()\n",
    "        with open(filename, \"wb\") as f:\n",
    "            f.write(response.content)\n",
    "        ds = xr.open_dataset(filename)\n",
    "        ds = ds.assign_coords(lon=(((ds.lon + 180) % 360) - 180))\n",
    "        ds_crop = ds[var].sel(lat=slice(*lat_bounds), lon=slice(*lon_bounds))\n",
    "        out_path = os.path.join(output_dir, f\"TerraClimate_{scenario}_{var}_{year}_CA.nc\")\n",
    "        ds_crop.to_netcdf(out_path)\n",
    "        print(f\"‚úÖ Saved to {out_path}\")\n",
    "        os.remove(filename)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed for {var} {year}: {e}\")\n",
    "\n",
    "# ========================\n",
    "# Run batch download\n",
    "# ========================\n",
    "for var in variables:\n",
    "    for year in years:\n",
    "        download_and_crop(var, year)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d8093e-d897-4b72-9956-071c96743104",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import os\n",
    "import requests\n",
    "\n",
    "# ========================\n",
    "# Settings\n",
    "# ========================\n",
    "scenario = \"plus4C\"\n",
    "prefix = \"4c\"\n",
    "output_dir = DATA_DIR / \"terra_climate_scenarios_ncss/plus4C\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "years = range(1985, 2015)\n",
    "lat_bounds = (25,10)\n",
    "lon_bounds = (-115, -50)\n",
    "\n",
    "\n",
    "# ========================\n",
    "# Helper function\n",
    "# ========================\n",
    "def download_and_crop(var, year):\n",
    "    filename = f\"TerraClimate_{prefix}_{var}_{year}.nc\"\n",
    "    url = f\"http://thredds.northwestknowledge.net:8080/thredds/fileServer/TERRACLIMATE_ALL/data_{scenario}/{filename}\"\n",
    "    print(f\"üîÑ Accessing {url}\")\n",
    "    try:\n",
    "        response = requests.get(url, timeout=60)\n",
    "        response.raise_for_status()\n",
    "        with open(filename, \"wb\") as f:\n",
    "            f.write(response.content)\n",
    "        ds = xr.open_dataset(filename)\n",
    "        ds = ds.assign_coords(lon=(((ds.lon + 180) % 360) - 180))\n",
    "        ds_crop = ds[var].sel(lat=slice(*lat_bounds), lon=slice(*lon_bounds))\n",
    "        out_path = os.path.join(output_dir, f\"TerraClimate_{scenario}_{var}_{year}_CA.nc\")\n",
    "        ds_crop.to_netcdf(out_path)\n",
    "        print(f\"‚úÖ Saved to {out_path}\")\n",
    "        os.remove(filename)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed for {var} {year}: {e}\")\n",
    "\n",
    "# ========================\n",
    "# Run batch download\n",
    "# ========================\n",
    "for var in variables:\n",
    "    for year in years:\n",
    "        download_and_crop(var, year)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cfea83-f052-4129-9e11-2629cfb852b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "def compute_suitability_variables(data_dir, output_path, file_prefix, start_year, end_year):\n",
    "    \"\"\"\n",
    "    Compute suitability variables from TerraClimate or scenario NetCDFs.\n",
    "    Includes bioclim-style quarterly metrics.\n",
    "    \"\"\"\n",
    "\n",
    "    # ------------------\n",
    "    # Helper: load + merge variable\n",
    "    # ------------------\n",
    "    def open_merge_var(varname):\n",
    "        files = sorted(glob.glob(f\"{data_dir}{file_prefix}_{varname}_*.nc\"))\n",
    "        if not files:\n",
    "            raise FileNotFoundError(f\"No files found for {varname} in {data_dir}\")\n",
    "        datasets = [xr.open_dataset(f)[varname] for f in files]\n",
    "        da = xr.concat(datasets, dim=\"time\")\n",
    "\n",
    "        # Create datetime index\n",
    "        start_file_year = int(files[0].split(\"_\")[-2])\n",
    "        time_index = pd.date_range(start=f\"{start_file_year}-01-01\", periods=da.sizes[\"time\"], freq=\"MS\")\n",
    "        da = da.assign_coords(time=(\"time\", time_index))\n",
    "\n",
    "        # Select time range\n",
    "        da = da.sel(time=slice(f\"{start_year}-01-01\", f\"{end_year}-12-31\"))\n",
    "        return da\n",
    "\n",
    "    # ------------------\n",
    "    # Load variables\n",
    "    # ------------------\n",
    "    tmin = open_merge_var(\"tmin\")\n",
    "    tmax = open_merge_var(\"tmax\")\n",
    "    ppt  = open_merge_var(\"ppt\")\n",
    "    pet  = open_merge_var(\"pet\")\n",
    "    aet  = open_merge_var(\"aet\")\n",
    "    deficit = open_merge_var(\"def\")\n",
    "    #srad = open_merge_var(\"srad\")\n",
    "\n",
    "    # ------------------\n",
    "    # Monthly climatologies\n",
    "    # ------------------\n",
    "    tmin_clim = tmin.groupby(\"time.month\").mean(dim=\"time\")\n",
    "    tmax_clim = tmax.groupby(\"time.month\").mean(dim=\"time\")\n",
    "    ppt_clim  = ppt.groupby(\"time.month\").mean(dim=\"time\")\n",
    "    pet_clim  = pet.groupby(\"time.month\").mean(dim=\"time\")\n",
    "    aet_clim  = aet.groupby(\"time.month\").mean(dim=\"time\")\n",
    "    deficit_clim = deficit.groupby(\"time.month\").mean(dim=\"time\")\n",
    "    #srad_clim = srad.groupby(\"time.month\").mean(dim=\"time\")\n",
    "\n",
    "    # ------------------\n",
    "    # Core metrics\n",
    "    # ------------------\n",
    "    mean_diurnal_range = (tmax_clim - tmin_clim).mean(dim=\"month\")\n",
    "    temp_ann_range = tmax_clim.max(dim=\"month\") - tmin_clim.min(dim=\"month\")\n",
    "    isothermality = (mean_diurnal_range / temp_ann_range) * 100\n",
    "    prec_seasonality = (ppt_clim.std(dim=\"month\") / ppt_clim.mean(dim=\"month\")) * 100\n",
    "\n",
    "    annual_pet = pet_clim.sum(dim=\"month\")\n",
    "    annual_aet = aet_clim.sum(dim=\"month\")\n",
    "    annual_def = deficit_clim.sum(dim=\"month\")\n",
    "    mean_srad = srad_clim.mean(dim=\"month\")\n",
    "\n",
    "    # ------------------\n",
    "    # Seasonal extremes (rolling 3-month windows)\n",
    "    # ------------------\n",
    "    tavg = (tmax + tmin) / 2\n",
    "    ppt_roll_sum = ppt.rolling(time=3, center=False).sum()\n",
    "    tavg_roll_mean = tavg.rolling(time=3, center=False).mean()\n",
    "\n",
    "    years = np.unique(ppt['time.year'])\n",
    "\n",
    "    # --- Driest month ---\n",
    "    prec_driest_month = ppt.groupby(\"time.year\").min(dim=\"time\").mean(dim=\"year\")\n",
    "\n",
    "    # --- Wettest month ---\n",
    "    prec_wettest_month = ppt.groupby(\"time.year\").max(dim=\"time\").mean(dim=\"year\")\n",
    "\n",
    "    # --- Mean Temp Driest Quarter ---\n",
    "    mt_driest_quarter_list = []\n",
    "    for y in years:\n",
    "        ppt_y = ppt_roll_sum.sel(time=str(y))\n",
    "        tavg_y = tavg_roll_mean.sel(time=str(y))\n",
    "        driest_idx = ppt_y.fillna(1e9).argmin(dim=\"time\")\n",
    "        mt_driest_quarter_list.append(tavg_y.isel(time=driest_idx))\n",
    "    mean_temp_driest_quarter = xr.concat(mt_driest_quarter_list, dim=\"year\").mean(dim=\"year\")\n",
    "\n",
    "    # --- Mean Temp Wettest Quarter (bio08) ---\n",
    "    mt_wettest_quarter_list = []\n",
    "    for y in years:\n",
    "        ppt_y = ppt_roll_sum.sel(time=str(y))\n",
    "        tavg_y = tavg_roll_mean.sel(time=str(y))\n",
    "        wettest_idx = ppt_y.fillna(-1e9).argmax(dim=\"time\")\n",
    "        mt_wettest_quarter_list.append(tavg_y.isel(time=wettest_idx))\n",
    "    mean_temp_wettest_quarter = xr.concat(mt_wettest_quarter_list, dim=\"year\").mean(dim=\"year\")\n",
    "\n",
    "    # --- Precip Warmest Quarter (bio18) ---\n",
    "    ppt_warmest_quarter_list = []\n",
    "    for y in years:\n",
    "        tavg_y = tavg_roll_mean.sel(time=str(y))\n",
    "        ppt_y = ppt_roll_sum.sel(time=str(y))\n",
    "        warmest_idx = tavg_y.fillna(-1e9).argmax(dim=\"time\")\n",
    "        ppt_warmest_quarter_list.append(ppt_y.isel(time=warmest_idx))\n",
    "    prec_warmest_quarter = xr.concat(ppt_warmest_quarter_list, dim=\"year\").mean(dim=\"year\")\n",
    "\n",
    "    # --- Precip Coldest Quarter (bio19) ---\n",
    "    ppt_coldest_quarter_list = []\n",
    "    for y in years:\n",
    "        tavg_y = tavg_roll_mean.sel(time=str(y))\n",
    "        ppt_y = ppt_roll_sum.sel(time=str(y))\n",
    "        coldest_idx = tavg_y.fillna(1e9).argmin(dim=\"time\")\n",
    "        ppt_coldest_quarter_list.append(ppt_y.isel(time=coldest_idx))\n",
    "    prec_coldest_quarter = xr.concat(ppt_coldest_quarter_list, dim=\"year\").mean(dim=\"year\")\n",
    "\n",
    "    # ------------------\n",
    "    # Combine into dataset\n",
    "    # ------------------\n",
    "    var_dict = {\n",
    "        \"MeanDiurnalRange\": mean_diurnal_range,\n",
    "        \"Isothermality\": isothermality,\n",
    "        \"PrecSeasonality\": prec_seasonality,\n",
    "        \"AnnualPET\": annual_pet,\n",
    "        \"AnnualAET\": annual_aet,\n",
    "        \"AnnualDeficit\": annual_def,\n",
    "        \"MeanSRAD\": mean_srad,\n",
    "        \"PrecDriestMonth\": prec_driest_month,\n",
    "        \"PrecWettestMonth\": prec_wettest_month,\n",
    "        \"MeanTempDriestQuarter\": mean_temp_driest_quarter,\n",
    "        \"MeanTempWettestQuarter\": mean_temp_wettest_quarter,\n",
    "        \"PrecWarmestQuarter\": prec_warmest_quarter,\n",
    "        \"PrecColdestQuarter\": prec_coldest_quarter\n",
    "    }\n",
    "\n",
    "    stack = xr.Dataset(var_dict)\n",
    "\n",
    "    # ------------------\n",
    "    # Save\n",
    "    # ------------------\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    stack.to_netcdf(output_path)\n",
    "    print(f\"‚úÖ Saved suitability variables to: {output_path}\")\n",
    "\n",
    "\n",
    "\n",
    "# # ===== Example usage =====\n",
    "# # Historical\n",
    "# compute_suitability_variables(\n",
    "#     data_dir=\"/Users/szelie/data/unu/terra_climate/\",\n",
    "#     output_path=\"/Users/szelie/data/unu/terra_climate/SuitabilityVariables_1990_2014.nc\",\n",
    "#     file_prefix=\"TerraClimate\",\n",
    "#     start_year=1990,\n",
    "#     end_year=2014\n",
    "# )\n",
    "\n",
    "# Future\n",
    "compute_suitability_variables(\n",
    "    data_dir=DATA_DIR / \"terra_climate_scenarios_ncss/plus4C/\",\n",
    "    output_path=DATA_DIR / \"terra_climate_scenarios_ncss/plus4C/SuitabilityVariables_plus4C_1990_2014.nc\",\n",
    "    file_prefix=\"TerraClimate_plus4C\",\n",
    "    start_year=1990,\n",
    "    end_year=2014\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb6bb64-d88b-46c2-81fb-60bf5f4ebb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "\n",
    "# Paths to your datasets\n",
    "hist_path = DATA_DIR / \"terra_climate/SuitabilityVariables_1990_2014.nc\"\n",
    "fut_path  = DATA_DIR / \"terra_climate_scenarios_ncss/plus2C/SuitabilityVariables_plus2C_1990_2014.nc\"\n",
    "\n",
    "# Open datasets\n",
    "hist_ds = xr.open_dataset(hist_path)\n",
    "fut_ds  = xr.open_dataset(fut_path)\n",
    "\n",
    "# Make sure they have the same variable names\n",
    "vars_to_compare = list(hist_ds.data_vars)\n",
    "\n",
    "# Collect statistics\n",
    "stats = []\n",
    "for var in vars_to_compare:\n",
    "    hist = hist_ds[var]\n",
    "    fut = fut_ds[var]\n",
    "\n",
    "    stats.append({\n",
    "        \"Variable\": var,\n",
    "        \"Hist_min\": float(hist.min()),\n",
    "        \"Fut_min\": float(fut.min()),\n",
    "        \"Hist_max\": float(hist.max()),\n",
    "        \"Fut_max\": float(fut.max()),\n",
    "        \"Hist_mean\": float(hist.mean()),\n",
    "        \"Fut_mean\": float(fut.mean()),\n",
    "        \"Hist_std\": float(hist.std()),\n",
    "        \"Fut_std\": float(fut.std()),\n",
    "        \"Mean_diff\": float(fut.mean() - hist.mean()),\n",
    "        \"Std_ratio\": float(fut.std() / hist.std()) if float(hist.std()) != 0 else None\n",
    "    })\n",
    "\n",
    "# Create dataframe and sort by largest mean difference\n",
    "stats_df = pd.DataFrame(stats).sort_values(by=\"Mean_diff\", key=abs, ascending=False)\n",
    "\n",
    "# Nice formatting\n",
    "pd.set_option(\"display.float_format\", lambda x: f\"{x:,.2f}\")\n",
    "print(stats_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56844da-7da0-4073-982a-6f19839201a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "\n",
    "# Path to fixed historical dataset\n",
    "nc_path = DATA_DIR / \"terra_climate/SuitabilityVariables_1990_2014.nc\"\n",
    "\n",
    "# Load dataset\n",
    "ds = xr.open_dataset(nc_path)\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = ds.to_dataframe().reset_index()\n",
    "\n",
    "# Keep only the data variable columns\n",
    "var_cols = list(ds.data_vars.keys())\n",
    "\n",
    "# Drop rows with NaN in any variable\n",
    "df_clean = df[var_cols].dropna()\n",
    "\n",
    "# Compute Pearson correlation\n",
    "corr = df_clean.corr(method=\"pearson\")\n",
    "\n",
    "# Display\n",
    "print(\"\\nüìä Correlation matrix:\\n\")\n",
    "print(corr.round(2))\n",
    "\n",
    "# Show high correlation pairs\n",
    "corr_threshold = 0.8\n",
    "print(f\"\\nüîç Highly correlated pairs (|r| > {corr_threshold}):\")\n",
    "for i, v1 in enumerate(var_cols):\n",
    "    for j, v2 in enumerate(var_cols):\n",
    "        if i < j and abs(corr.loc[v1, v2]) > corr_threshold:\n",
    "            print(f\"{v1} ‚Üî {v2}: r = {corr.loc[v1, v2]:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
